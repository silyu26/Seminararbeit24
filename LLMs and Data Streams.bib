@Article{Liu_2023,
  author    = {Liu, Yiheng and Han, Tianle and Ma, Siyuan and Zhang, Jiayue and Yang, Yuanyuan and Tian, Jiaming and He, Hao and Li, Antong and He, Mengshen and Liu, Zhengliang and Wu, Zihao and Zhao, Lin and Zhu, Dajiang and Li, Xiang and Qiang, Ning and Shen, Dingang and Liu, Tianming and Ge, Bao},
  journal   = {Meta-Radiology},
  title     = {Summary of ChatGPT-Related research and perspective towards the future of large language models},
  year      = {2023},
  issn      = {2950-1628},
  month     = sep,
  number    = {2},
  pages     = {100017},
  volume    = {1},
  abstract  = {This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.},
  doi       = {https://doi.org/10.1016/j.metrad.2023.100017},
  file      = {:C\:/Users/11584/Downloads/Summary ChatGPT.pdf:PDF},
  publisher = {Elsevier BV},
}

@Misc{https://doi.org/10.48550/arxiv.2307.08225,
  author    = {Zhang, Shuhao and Zeng, Xianzhi and Wu, Yuhao and Yang, Zhonghao},
  title     = {Harnessing Scalable Transactional Stream Processing for Managing Large Language Models [Vision]},
  year      = {2023},
  abstract  = {Large Language Models (LLMs) have demonstrated extraordinary performance across a broad array of applications, from traditional language processing tasks to interpreting structured sequences like time-series data. Yet, their effectiveness in fast-paced, online decision-making environments requiring swift, accurate, and concurrent responses poses a significant challenge. This paper introduces TStreamLLM, a revolutionary framework integrating Transactional Stream Processing (TSP) with LLM management to achieve remarkable scalability and low latency. By harnessing the scalability, consistency, and fault tolerance inherent in TSP, TStreamLLM aims to manage continuous & concurrent LLM updates and usages efficiently. We showcase its potential through practical use cases like real-time patient monitoring and intelligent traffic management. The exploration of synergies between TSP and LLM management can stimulate groundbreaking developments in AI and database research. This paper provides a comprehensive overview of challenges and opportunities in this emerging field, setting forth a roadmap for future exploration and development.},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {https://doi.org/10.48550/arXiv.2307.08225},
  file      = {:C\:/Users/11584/Downloads/TStreamLLM.pdf:PDF},
  keywords  = {Databases (cs.DB), Artificial Intelligence (cs.AI), Distributed, Parallel, and Cluster Computing (cs.DC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Zhang_2024,
  author    = {Zhang, Kunpeng and Zhou, Feng and Wu, Lan and Xie, Na and He, Zhengbing},
  journal   = {Information Fusion},
  title     = {Semantic understanding and prompt engineering for large-scale traffic data imputation},
  year      = {2024},
  issn      = {1566-2535},
  month     = feb,
  pages     = {102038},
  volume    = {102},
  abstract  = {Intelligent Transportation Systems (ITS) face the formidable challenge of large-scale missing data, particularly in the imputation of traffic data. Existing studies have mainly relied on modeling network-level spatiotemporal correlations to address this issue. However, these methods often overlook the rich semantic information (e.g., road infrastructure, sensor location, etc.) inherent in road networks when capturing network-wide spatiotemporal correlations. We address this limitation by presenting the Graph Transformer-based Traffic Data Imputation (GT-TDI) model, which imputes missing values in extensive traffic data by leveraging spatiotemporal semantic understanding of road networks. The proposed model leverages semantic descriptions that capture the spatial and temporal dynamics of traffic across road networks, enhancing its capacity to infer comprehensive spatiotemporal relationships. Moreover, to augment the model’s capabilities, we employ a Large Language Model (LLM) and prompt engineering to enable natural and intuitive interactions with the traffic data imputation system, allowing users to query and request in plain language, without requiring expert knowledge or complex mathematical models. The proposed model, GT-TDI, utilizes Graph Neural Networks (GNN) and Transformer architectures to perform large-scale traffic data imputation using deficient observations, sensor social connectivity, and semantic descriptions as inputs. We evaluate the GT-TDI model on the PeMS freeway dataset and benchmark it against cutting-edge models. The experimental evidence demonstrates that GT-TDI surpasses the cutting-edge approaches in scenarios with intricate patterns and varying rates of missing data.},
  doi       = {https://doi.org/10.1016/j.inffus.2023.102038},
  file      = {:C\:/Users/11584/Downloads/Traffic data.pdf:PDF},
  publisher = {Elsevier BV},
}

@Article{https://doi.org/10.48550/arxiv.2307.14385,
  author    = {Xu, Xuhai and Yao, Bingsheng and Dong, Yuanzhe and Gabriel, Saadia and Yu, Hong and Hendler, James and Ghassemi, Marzyeh and Dey, Anind K. and Wang, Dakuo},
  title     = {Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data},
  year      = {2023},
  abstract  = {Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {https://doi.org/10.48550/arXiv.2307.14385},
  file      = {:C\:/Users/11584/Downloads/Mental Health.pdf:PDF},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences, H.5.2; I.2.m, 68U35},
  publisher = {arXiv},
}

@Misc{https://doi.org/10.48550/arxiv.2403.06139,
  author    = {Zhang, Xin and Zhang, Linhai and Zhou, Deyu and Xu, Guoqiang},
  title     = {Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity},
  year      = {2024},
  abstract  = {Due to the sparsity of user data, sentiment analysis on user reviews in e-commerce platforms often suffers from poor performance, especially when faced with extremely sparse user data or long-tail labels. Recently, the emergence of LLMs has introduced new solutions to such problems by leveraging graph structures to generate supplementary user profiles. However, previous approaches have not fully utilized the graph understanding capabilities of LLMs and have struggled to adapt to complex streaming data environments. In this work, we propose a fine-grained streaming data synthesis framework that categorizes sparse users into three categories: Mid-tail, Long-tail, and Extreme. Specifically, we design LLMs to comprehensively understand three key graph elements in streaming data, including Local-global Graph Understanding, Second-Order Relationship Extraction, and Product Attribute Understanding, which enables the generation of high-quality synthetic data to effectively address sparsity across different categories. Experimental results on three real datasets demonstrate significant performance improvements, with synthesized data contributing to MSE reductions of 45.85%, 3.16%, and 62.21%, respectively.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2403.06139},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{https://doi.org/10.48550/arxiv.2402.01364,
  author    = {Wu, Tongtong and Luo, Linhao and Li, Yuan-Fang and Pan, Shirui and Vu, Thuy-Trang and Haffari, Gholamreza},
  title     = {Continual Learning for Large Language Models: A Survey},
  year      = {2024},
  abstract  = {Large language models (LLMs) are not amenable to frequent re-training, due to high training costs arising from their massive scale. However, updates are necessary to endow LLMs with new skills and keep them up-to-date with rapidly evolving human knowledge. This paper surveys recent works on continual learning for LLMs. Due to the unique nature of LLMs, we catalog continue learning techniques in a novel multi-staged categorization scheme, involving continual pretraining, instruction tuning, and alignment. We contrast continual learning for LLMs with simpler adaptation methods used in smaller models, as well as with other enhancement strategies like retrieval-augmented generation and model editing. Moreover, informed by a discussion of benchmarks and evaluation, we identify several challenges and future work directions for this crucial task.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2402.01364},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{https://doi.org/10.48550/arxiv.2005.14165,
  author    = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  title     = {Language Models are Few-Shot Learners},
  year      = {2020},
  abstract  = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2005.14165},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Gama_2012,
  author    = {Gama, João and Sebastião, Raquel and Rodrigues, Pedro Pereira},
  journal   = {Machine Learning},
  title     = {On evaluating stream learning algorithms},
  year      = {2012},
  issn      = {1573-0565},
  month     = oct,
  number    = {3},
  pages     = {317--346},
  volume    = {90},
  abstract  = {Most streaming decision models evolve continuously over time, run in resource-aware environments, and detect and react to changes in the environment generating data. One important issue, not yet convincingly addressed, is the design of experimental work to evaluate and compare decision models that evolve over time. This paper proposes a general framework for assessing predictive stream learning algorithms. We defend the use of prequential error with forgetting mechanisms to provide reliable error estimators. We prove that, in stationary data and for consistent learning algorithms, the holdout estimator, the prequential error and the prequential error estimated over a sliding window or using fading factors, all converge to the Bayes error. The use of prequential error with forgetting mechanisms reveals to be advantageous in assessing performance and in comparing stream learning algorithms. It is also worthwhile to use the proposed methods for hypothesis testing and for change detection. In a set of experiments in drift scenarios, we evaluate the ability of a standard change detection algorithm to detect change using three prequential error estimators. These experiments point out that the use of forgetting mechanisms (sliding windows or fading factors) are required for fast and efficient change detection. In comparison to sliding windows, fading factors are faster and memoryless, both important requirements for streaming applications. Overall, this paper is a contribution to a discussion on best practice for performance assessment when learning is a continuous process, and the decision models are dynamic and evolve over time.},
  doi       = {https://doi.org/10.1007/s10994-012-5320-9},
  publisher = {Springer Science and Business Media LLC},
}

@Article{https://doi.org/10.48550/arxiv.2110.03215,
  author    = {Jang, Joel and Ye, Seonghyeon and Yang, Sohee and Shin, Joongbo and Han, Janghoon and Kim, Gyeonghun and Choi, Stanley Jungkyu and Seo, Minjoon},
  title     = {Towards Continual Knowledge Learning of Language Models},
  year      = {2021},
  abstract  = {Large Language Models (LMs) are known to encode world knowledge in their parameters as they pretrain on a vast amount of web corpus, which is often utilized for performing knowledge-dependent downstream tasks such as question answering, fact-checking, and open dialogue. In real-world scenarios, the world knowledge stored in the LMs can quickly become outdated as the world changes, but it is non-trivial to avoid catastrophic forgetting and reliably acquire new knowledge while preserving invariant knowledge. To push the community towards better maintenance of ever-changing LMs, we formulate a new continual learning (CL) problem called Continual Knowledge Learning (CKL). We construct a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. We adopt applicable recent methods from literature to create several strong baselines. Through extensive experiments, we find that CKL exhibits unique challenges that are not addressed in previous CL setups, where parameter expansion is necessary to reliably retain and learn knowledge simultaneously. By highlighting the critical causes of knowledge forgetting, we show that CKL is a challenging and important problem that helps us better understand and train ever-changing LMs.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2110.03215},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@InBook{https://doi.org/10.4230/dfu.vol5.10452.275,
  author    = {Geisler, Sandra},
  publisher = {Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
  title     = {Data Stream Management Systems},
  year      = {2013},
  abstract  = {In many application fields, such as production lines or stock analysis, it is substantial to create
and process high amounts of data at high rates. Such continuous data flows with unknown
size and end are also called data streams. The processing and analysis of data streams are a
challenge for common data management systems as they have to operate and deliver results in real
time. Data Stream Management Systems (DSMS), as an advancement of database management
systems, have been implemented to deal with these issues. DSMS have to adapt to the notion
of data streams on various levels, such as query languages, processing or optimization. In this
chapter we give an overview of the basics of data streams, architecture principles of DSMS and
the used query languages. Furthermore, we specifically detail data quality aspects in DSMS as
these play an important role for various applications based on data streams. Finally, the chapter
also includes a list of research and commercial DSMS and their key properties.},
  copyright = {Creative Commons Attribution 3.0 Unported license},
  doi       = {http://dx.doi.org/10.4230/DFU.Vol5.10452.275},
  keywords  = {Data Streams, Data Stream Management, Data Quality, Query Languages},
  language  = {en},
}

@Article{Kasneci_2023,
  author    = {Kasneci, Enkelejda and Sessler, Kathrin and Küchemann, Stefan and Bannert, Maria and Dementieva, Daryna and Fischer, Frank and Gasser, Urs and Groh, Georg and Günnemann, Stephan and Hüllermeier, Eyke and Krusche, Stephan and Kutyniok, Gitta and Michaeli, Tilman and Nerdel, Claudia and Pfeffer, Jürgen and Poquet, Oleksandra and Sailer, Michael and Schmidt, Albrecht and Seidel, Tina and Stadler, Matthias and Weller, Jochen and Kuhn, Jochen and Kasneci, Gjergji},
  journal   = {Learning and Individual Differences},
  title     = {ChatGPT for good? On opportunities and challenges of large language models for education},
  year      = {2023},
  issn      = {1041-6080},
  month     = apr,
  pages     = {102274},
  volume    = {103},
  abstract  = {Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This commentary presents the potential benefits and challenges of educational applications of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.},
  doi       = {https://doi.org/10.1016/j.lindif.2023.102274},
  publisher = {Elsevier BV},
}

@Article{Thirunavukarasu_2023,
  author    = {Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  journal   = {Nature Medicine},
  title     = {Large language models in medicine},
  year      = {2023},
  issn      = {1546-170X},
  month     = jul,
  number    = {8},
  pages     = {1930--1940},
  volume    = {29},
  abstract  = {Large language models (LLMs) can respond to free-text queries without being specifically trained in the task in question, causing excitement and concern about their use in healthcare settings. ChatGPT is a generative artificial intelligence (AI) chatbot produced through sophisticated fine-tuning of an LLM, and other tools are emerging through similar developmental processes. Here we outline how LLM applications such as ChatGPT are developed, and we discuss how they are being leveraged in clinical settings. We consider the strengths and limitations of LLMs and their potential to improve the efficiency and effectiveness of clinical, educational and research work in medicine. LLM chatbots have already been deployed in a range of biomedical contexts, with impressive but mixed results. This review acts as a primer for interested clinicians, who will determine if and how LLM technology is used in healthcare for the benefit of patients and practitioners.},
  doi       = {https://doi.org/10.1038/s41591-023-02448-8},
  publisher = {Springer Science and Business Media LLC},
}

@Article{Chang_2024,
  author    = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
  journal   = {ACM Transactions on Intelligent Systems and Technology},
  title     = {A Survey on Evaluation of Large Language Models},
  year      = {2024},
  issn      = {2157-6912},
  month     = mar,
  number    = {3},
  pages     = {1--45},
  volume    = {15},
  abstract  = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey},
  doi       = {https://doi.org/10.1145/3641289},
  publisher = {Association for Computing Machinery (ACM)},
}

@Misc{https://doi.org/10.48550/arxiv.1810.04805,
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year      = {2018},
  abstract  = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.
BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  comment   = {This paper introduces BERT (Bidirectional Encoder Representations from Transformers), a model that has significantly advanced the field of NLP by pre-training a deep bidirectional representation of language.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.1810.04805},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Yenduri_2024,
  author    = {Yenduri, Gokul and Ramalingam, M and Chemmalar Selvi, G and Supriya, Y and Srivastava, Gautam and Maddikunta, Praveen Kumar Reddy and Deepti Raj, G and Jhaveri, Rutvij H and Prabadevi, B and Wang, Weizheng and Vasilakos, Athanasios V. and Gadekallu, Thippa Reddy},
  journal   = {IEEE Access},
  title     = {GPT (Generative Pre-trained Transformer) – A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions},
  year      = {2024},
  issn      = {2169-3536},
  pages     = {1--1},
  abstract  = {The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.},
  doi       = {10.1109/ACCESS.2024.3389497},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Misc{https://doi.org/10.48550/arxiv.2104.08691,
  author    = {Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  title     = {The Power of Scale for Parameter-Efficient Prompt Tuning},
  year      = {2021},
  abstract  = {In this work, we explore "prompt tuning", a simple yet effective mechanism for learning "soft prompts" to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signal from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's "few-shot" learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method "closes the gap" and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant in that large models are costly to share and serve, and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed "prefix tuning" of Li and Liang (2021), and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer, as compared to full model tuning.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2104.08691},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{https://doi.org/10.48550/arxiv.1901.11117,
  author    = {So, David R. and Liang, Chen and Le, Quoc V.},
  title     = {The Evolved Transformer},
  year      = {2019},
  abstract  = {Recent works have highlighted the strength of the Transformer architecture on sequence tasks while, at the same time, neural architecture search (NAS) has begun to outperform human-designed models. Our goal is to apply NAS to search for a better alternative to the Transformer. We first construct a large search space inspired by the recent advances in feed-forward sequence models and then run evolutionary architecture search with warm starting by seeding our initial population with the Transformer. To directly search on the computationally expensive WMT 2014 English-German translation task, we develop the Progressive Dynamic Hurdles method, which allows us to dynamically allocate more resources to more promising candidate models. The architecture found in our experiments -- the Evolved Transformer -- demonstrates consistent improvement over the Transformer on four well-established language tasks: WMT 2014 English-German, WMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size, the Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8 on WMT'14 English-German; at smaller sizes, it achieves the same quality as the original "big" Transformer with 37.6% less parameters and outperforms the Transformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
  doi       = {https://doi.org/10.48550/arXiv.1901.11117},
  keywords  = {Machine Learning (cs.LG), Computation and Language (cs.CL), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{https://doi.org/10.48550/arxiv.2403.00782,
  author    = {Tong, Hanshuang and Li, Jun and Wu, Ning and Gong, Ming and Zhang, Dongmei and Zhang, Qi},
  title     = {Ploutos: Towards interpretable stock movement prediction with financial large language model},
  year      = {2024},
  abstract  = {Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates interpretable rationales. To generate accurate and faithful rationales, the training strategy of PloutosGPT leverage rearview-mirror prompting mechanism to guide GPT-4 to generate rationales, and a dynamic token weighting mechanism to finetune LLM by increasing key tokens weight. Extensive experiments show our framework outperforms the state-of-the-art methods on both prediction accuracy and interpretability.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2403.00782},
  keywords  = {Statistical Finance (q-fin.ST), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Economics and business, FOS: Economics and business, FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Zhao_2022,
  author    = {Zhao, Feng and Li, Xinning and Gao, Yating and Li, Ying and Feng, Zhiquan and Zhang, Caiming},
  journal   = {Expert Systems with Applications},
  title     = {Multi-layer features ablation of BERT model and its application in stock trend prediction},
  year      = {2022},
  issn      = {0957-4174},
  month     = nov,
  pages     = {117958},
  volume    = {207},
  abstract  = {Stock comments published by experts are important references for accurate stock trends prediction. How to comprehensively and accurately capture the topic of expert stock comments is an important issue which belongs to text classification. The Bidirectional Encoder Representations from Transformers (BERT) pretrained language model is widely used for text classification, due to its high identification accuracy. However, BERT has some limitations. First, it only utilizes fixed length text, leading to suboptimal performance in long text information exploration. Second, it only relies on the features extracted from the last layer, resulting in incomprehensive classification features. To tackle these issues, we propose a multi-layer features ablation study of BERT model for accurate identification of stock comments’ themes. Specifically, we firstly divide the original text to meet the length requirement of the BERT model based on sliding window technology. In this way, we can enlarge the sample size which is beneficial for reducing the over-fitting problem. At the same time, by dividing the long text into multiple short texts, all the information of the long text can be comprehensively captured through the synthesis of the subject information of multiple short texts. In addition, we extract the output features of each layer in the BERT model and apply the ablation strategy to extract more effective information in these features. Experimental results demonstrate that compared with non-intercepted comments, the topic recognition accuracy is improved by intercepting stock comments based on sliding window technology. It proves that intercepting text can improve the performance of text classification. Compared with the BERT, the multi-layer features ablation study we present in the paper further improves the performance in the topic recognition of stock comments, and can provide reference for the majority of investors. Our study has better performance and practicability on stock trend prediction by stock comments topic recognition.},
  doi       = {https://doi.org/10.1016/j.eswa.2022.117958},
  publisher = {Elsevier BV},
}

@Misc{https://doi.org/10.48550/arxiv.1908.10063,
  author    = {Araci, Dogu},
  title     = {FinBERT: Financial Sentiment Analysis with Pre-trained Language Models},
  year      = {2019},
  abstract  = {Financial sentiment analysis is a challenging task due to the specialized language and lack of labeled data in that domain. General-purpose models are not effective enough because of the specialized language used in a financial context. We hypothesize that pre-trained language models can help with this problem because they require fewer labeled examples and they can be further trained on domain-specific corpora. We introduce FinBERT, a language model based on BERT, to tackle NLP tasks in the financial domain. Our results show improvement in every measured metric on current state-of-the-art results for two financial sentiment analysis datasets. We find that even with a smaller training set and fine-tuning only a part of the model, FinBERT outperforms state-of-the-art machine learning methods.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.1908.10063},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{https://doi.org/10.48550/arxiv.2403.02221,
  author    = {Ren, Yilong and Chen, Yue and Liu, Shuai and Wang, Boyue and Yu, Haiyang and Cui, Zhiyong},
  title     = {TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language Models},
  year      = {2024},
  abstract  = {Traffic prediction constitutes a pivotal facet within the purview of Intelligent Transportation Systems (ITS), and the attainment of highly precise predictions holds profound significance for efficacious traffic management. The precision of prevailing deep learning-driven traffic prediction models typically sees an upward trend with a rise in the volume of training data. However, the procurement of comprehensive spatiotemporal datasets for traffic is often fraught with challenges, primarily stemming from the substantial costs associated with data collection and retention. Consequently, developing a model that can achieve accurate predictions and good generalization ability in areas with limited historical traffic data is a challenging problem. It is noteworthy that the rapidly advancing pretrained Large Language Models (LLMs) of recent years have demonstrated exceptional proficiency in cross-modality knowledge transfer and few-shot learning. Recognizing the sequential nature of traffic data, similar to language, we introduce TPLLM, a novel traffic prediction framework leveraging LLMs. In this framework, we construct a sequence embedding layer based on Convolutional Neural Networks (CNNs) and a graph embedding layer based on Graph Convolutional Networks (GCNs) to extract sequence features and spatial features, respectively. These are subsequently integrated to form inputs that are suitable for LLMs. A Low-Rank Adaptation (LoRA) fine-tuning approach is applied to TPLLM, thereby facilitating efficient learning and minimizing computational demands. Experiments on two real-world datasets demonstrate that TPLLM exhibits commendable performance in both full-sample and few-shot prediction scenarios, effectively supporting the development of ITS in regions with scarce historical traffic data.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2403.02221},
  keywords  = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Misc{https://doi.org/10.48550/arxiv.2401.10134,
  author    = {Liu, Chenxi and Yang, Sun and Xu, Qianxiong and Li, Zhishuai and Long, Cheng and Li, Ziyue and Zhao, Rui},
  title     = {Spatial-Temporal Large Language Model for Traffic Prediction},
  year      = {2024},
  abstract  = {Traffic prediction, a critical component for intelligent transportation systems, endeavors to foresee future traffic at specific locations using historical data. Although existing traffic prediction models often emphasize developing complex neural network structures, their accuracy has not seen improvements accordingly. Recently, Large Language Models (LLMs) have shown outstanding capabilities in time series analysis. Differing from existing models, LLMs progress mainly through parameter expansion and extensive pre-training while maintaining their fundamental structures. In this paper, we propose a Spatial-Temporal Large Language Model (ST-LLM) for traffic prediction. Specifically, ST-LLM redefines the timesteps at each location as tokens and incorporates a spatial-temporal embedding module to learn the spatial location and global temporal representations of tokens. Then these representations are fused to provide each token with unified spatial and temporal information. Furthermore, we propose a novel partially frozen attention strategy of the LLM, which is designed to capture spatial-temporal dependencies for traffic prediction. Comprehensive experiments on real traffic datasets offer evidence that ST-LLM outperforms state-of-the-art models. Notably, the ST-LLM also exhibits robust performance in both few-shot and zero-shot prediction scenarios.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2401.10134},
  keywords  = {Machine Learning (cs.LG), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Yang_2022,
  author    = {Yang, Xi and Chen, Aokun and PourNejatian, Nima and Shin, Hoo Chang and Smith, Kaleb E. and Parisien, Christopher and Compas, Colin and Martin, Cheryl and Costa, Anthony B. and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Harle, Christopher A. and Lipori, Gloria and Mitchell, Duane A. and Hogan, William R. and Shenkman, Elizabeth A. and Bian, Jiang and Wu, Yonghui},
  journal   = {npj Digital Medicine},
  title     = {A large language model for electronic health records},
  year      = {2022},
  issn      = {2398-6352},
  month     = dec,
  number    = {1},
  volume    = {5},
  doi       = {https://doi.org/10.1038/s41746-022-00742-2},
  publisher = {Springer Science and Business Media LLC},
}

@Misc{https://doi.org/10.48550/arxiv.2308.04014,
  author    = {Gupta, Kshitij and Thérien, Benjamin and Ibrahim, Adam and Richter, Mats L. and Anthony, Quentin and Belilovsky, Eugene and Rish, Irina and Lesort, Timothée},
  title     = {Continual Pre-Training of Large Language Models: How to (re)warm your model?},
  year      = {2023},
  abstract  = {Large language models (LLMs) are routinely pre-trained on billions of tokens, only to restart the process over again once new data becomes available. A much cheaper and more efficient solution would be to enable the continual pre-training of these models, i.e. updating pre-trained models with new data instead of re-training them from scratch. However, the distribution shift induced by novel data typically results in degraded performance on past data. Taking a step towards efficient continual pre-training, in this work, we examine the effect of different warm-up strategies. Our hypothesis is that the learning rate must be re-increased to improve compute efficiency when training on a new dataset. We study the warmup phase of models pre-trained on the Pile (upstream data, 300B tokens) as we continue to pre-train on SlimPajama (downstream data, 297B tokens), following a linear warmup and cosine decay schedule. We conduct all experiments on the Pythia 410M language model architecture and evaluate performance through validation perplexity. We experiment with different pre-training checkpoints, various maximum learning rates, and various warmup lengths. Our results show that while rewarming models first increases the loss on upstream and downstream data, in the longer run it improves the downstream performance, outperforming models trained from scratch–even for a large downstream dataset.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {https://doi.org/10.48550/arXiv.2308.04014},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Comment{jabref-meta: databaseType:bibtex;}
